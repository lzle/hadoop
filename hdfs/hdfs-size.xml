<!-- 每个datanode复制副本并发数 -->
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>6</value>
</property>

<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>10</value>
</property>

<!-- 每次筛选副本数 = numlive * this -->
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>10</value>
</property>

<!-- 心跳重新检查时间(ms),超过两倍的时间判断节点失效 -->
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>900000</value>
</property>

<!-- 每次筛选无效副本数 = Math.ceil(numlive * this) -->
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32f</value>
</property>

<!-- 每个心跳删除命令由NameNode发送到DataNode的最大无效块数 -->
<property>
<name>dfs.block.invalidate.limit</name>
<value>16</value>
</property>

<!-- 处理Client Rpc的请求的线程数，建议值ln(number of DataNodes in this HDFS service) * 20 -->
<property>
<name>dfs.namenode.handler.count</name>
<value>100</value>
</property>

<!-- DataNode Rpc线程并发数，处理NameNode请求 -->
<property>
<name>dfs.datanode.handler.count</name>
<value>10</value>
</property>

<!-- DataNode处理数据传输的线程数 -->
<property>
<name>dfs.datanode.max.transfer.threads</name>
<value>4096</value>
</property>

<!-- 关闭本地写 -->
<property>
<name>dfs.namenode.block-placement-policy.default.prefer-local-node</name>
<value>false</value>
</property>

<!-- 优先筛选更低使用率的datanode -->
<property>
  <name>dfs.block.replicator.classname</name>
  <value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>

<property>
  <name>dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction</name>
  <value>0.6</value>
  <description>
    Special value between 0 and 1, noninclusive.  Increases chance of
    placing blocks on Datanodes with less disk space used.
  </description>
</property>